{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17d5be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('book')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20820516",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9696c312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 260819\n",
      "Length of text: 141576\n",
      "Length of text: 44764\n",
      "Length of text: 156288\n",
      "Length of text: 45010\n",
      "Length of text: 16967\n",
      "Length of text: 100676\n",
      "Length of text: 4867\n",
      "Length of text: 69213\n"
     ]
    }
   ],
   "source": [
    "def length_of_text(text):\n",
    "    return len(text)\n",
    "\n",
    "for text in [text1, text2, text3, text4, text5, text6, text7, text8, text9]:\n",
    "    print(f\"Length of text: {length_of_text(text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74f38763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words in text:  19317\n",
      "Unique words in text:  6833\n",
      "Unique words in text:  2789\n",
      "Unique words in text:  10200\n",
      "Unique words in text:  6066\n",
      "Unique words in text:  2166\n",
      "Unique words in text:  12408\n",
      "Unique words in text:  1108\n",
      "Unique words in text:  6807\n"
     ]
    }
   ],
   "source": [
    "# Unique words in each text\n",
    "def unique_words(text):\n",
    "    return set(text)\n",
    "for text in [text1, text2, text3, text4, text5, text6, text7, text8, text9]: \n",
    "    print(f\"Unique words in text:  {len(unique_words(text))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e1f51a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lexical diversity of text: 13.502\n",
      "Lexical diversity of text: 20.719\n",
      "Lexical diversity of text: 16.050\n",
      "Lexical diversity of text: 15.322\n",
      "Lexical diversity of text: 7.420\n",
      "Lexical diversity of text: 7.833\n",
      "Lexical diversity of text: 8.114\n",
      "Lexical diversity of text: 4.393\n",
      "Lexical diversity of text: 10.168\n"
     ]
    }
   ],
   "source": [
    "def lexical_diversity(text):\n",
    "    return len(text) / len(set(text))\n",
    "\n",
    "for text in [text1, text2, text3, text4, text5, text6, text7, text8, text9]:\n",
    "    print(f\"Lexical diversity of text: {lexical_diversity(text):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253daec8",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03781ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import gutenberg, brown,webtext , nps_chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8879826a",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora = [\n",
    "    ('gutenberg', gutenberg),\n",
    "    ('brown', brown),\n",
    "    ('webtext', webtext),\n",
    "    ('nps_chat', nps_chat)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "445185c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_table = []\n",
    "for name, corpus in corpora:\n",
    "    total_characters = sum(len(corpus.raw(fileid)) for fileid in corpus.fileids())\n",
    "    total_words = sum(len(corpus.words(fileid)) for fileid in corpus.fileids())\n",
    "    try:\n",
    "        total_sentences = sum(len(corpus.sents(fileid)) for fileid in corpus.fileids())\n",
    "    except AttributeError:\n",
    "        total_sentences = sum(len(corpus.posts(fileid)) for fileid in corpus.fileids())\n",
    "\n",
    "    unique_words = set(w.lower() for fileid in corpus.fileids() for w in corpus.words(fileid) if w.isalpha())\n",
    "    all_words = [w for fileid in corpus.fileids() for w in corpus.words(fileid) if w.isalpha()]\n",
    "    avg_word_length = sum(len(w) for w in all_words) / len(all_words) if all_words else 0\n",
    "    avg_sent_len = total_words / total_sentences if total_sentences else 0\n",
    "    lexical_richness = len(all_words) / len(unique_words) if unique_words else 0\n",
    "\n",
    "    summary_table.append({\n",
    "        'corpus': name,\n",
    "        'characters': total_characters,\n",
    "        'words': total_words,\n",
    "        'sentences': total_sentences,\n",
    "        'unique_words': len(unique_words),\n",
    "        'avg_word_length': avg_word_length,\n",
    "        'avg_sentence_length': avg_sent_len,\n",
    "        'lexical_richness': lexical_richness\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0a2ce3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12300\\4012637384.py\", line 1, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\__init__.py\", line 38, in <module>\n",
      "    from pandas.compat import (\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\compat\\__init__.py\", line 29, in <module>\n",
      "    from pandas.compat.pyarrow import (\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\compat\\pyarrow.py\", line 8, in <module>\n",
      "    import pyarrow as pa\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\pyarrow\\__init__.py\", line 65, in <module>\n",
      "    import pyarrow.lib as _lib\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.2.6 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\numpy\\core\\_multiarray_umath.py:44\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr_name)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(msg \u001b[38;5;241m+\u001b[39m tb_msg)\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m     46\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.2.6 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12300\\4012637384.py\", line 1, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\__init__.py\", line 61, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\api.py\", line 9, in <module>\n",
      "    from pandas.core.dtypes.dtypes import (\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\dtypes\\dtypes.py\", line 24, in <module>\n",
      "    from pandas._libs import (\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\pyarrow\\__init__.py\", line 65, in <module>\n",
      "    import pyarrow.lib as _lib\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.2.6 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\numpy\\core\\_multiarray_umath.py:44\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr_name)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(msg \u001b[38;5;241m+\u001b[39m tb_msg)\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m     46\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.2.6 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12300\\4012637384.py\", line 1, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\__init__.py\", line 61, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\arrays\\__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\arrays\\arrow\\__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\arrays\\arrow\\array.py\", line 53, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\ops\\__init__.py\", line 8, in <module>\n",
      "    from pandas.core.ops.array_ops import (\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\ops\\array_ops.py\", line 56, in <module>\n",
      "    from pandas.core.computation import expressions\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\computation\\expressions.py\", line 21, in <module>\n",
      "    from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\computation\\check.py\", line 5, in <module>\n",
      "    ne = import_optional_dependency(\"numexpr\", errors=\"warn\")\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\compat\\_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\importlib\\__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numexpr\\__init__.py\", line 24, in <module>\n",
      "    from numexpr.interpreter import MAX_THREADS, use_vml, __BLOCK_SIZE1__\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12300\\4012637384.py\", line 1, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\__init__.py\", line 61, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\arrays\\__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\arrays\\arrow\\__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\arrays\\arrow\\array.py\", line 67, in <module>\n",
      "    from pandas.core.arrays.masked import BaseMaskedArray\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\arrays\\masked.py\", line 61, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\nanops.py\", line 52, in <module>\n",
      "    bn = import_optional_dependency(\"bottleneck\", errors=\"warn\")\n",
      "  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\compat\\_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\importlib\\__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\bottleneck\\__init__.py\", line 7, in <module>\n",
      "    from .move import (move_argmax, move_argmin, move_max, move_mean, move_median,\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.2.6 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\numpy\\core\\_multiarray_umath.py:44\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr_name)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(msg \u001b[38;5;241m+\u001b[39m tb_msg)\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m     46\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.2.6 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus</th>\n",
       "      <th>characters</th>\n",
       "      <th>words</th>\n",
       "      <th>sentences</th>\n",
       "      <th>unique_words</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>lexical_richness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gutenberg</td>\n",
       "      <td>11793318</td>\n",
       "      <td>2621613</td>\n",
       "      <td>98552</td>\n",
       "      <td>41487</td>\n",
       "      <td>4.178884</td>\n",
       "      <td>26.601317</td>\n",
       "      <td>51.471545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>brown</td>\n",
       "      <td>9964284</td>\n",
       "      <td>1161192</td>\n",
       "      <td>57340</td>\n",
       "      <td>40234</td>\n",
       "      <td>4.683249</td>\n",
       "      <td>20.250994</td>\n",
       "      <td>24.400159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>webtext</td>\n",
       "      <td>1726164</td>\n",
       "      <td>396733</td>\n",
       "      <td>25733</td>\n",
       "      <td>16453</td>\n",
       "      <td>4.262979</td>\n",
       "      <td>15.417285</td>\n",
       "      <td>18.601775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nps_chat</td>\n",
       "      <td>2568552</td>\n",
       "      <td>45010</td>\n",
       "      <td>10567</td>\n",
       "      <td>4671</td>\n",
       "      <td>3.813103</td>\n",
       "      <td>4.259487</td>\n",
       "      <td>7.342539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      corpus  characters    words  sentences  unique_words  avg_word_length  \\\n",
       "0  gutenberg    11793318  2621613      98552         41487         4.178884   \n",
       "1      brown     9964284  1161192      57340         40234         4.683249   \n",
       "2    webtext     1726164   396733      25733         16453         4.262979   \n",
       "3   nps_chat     2568552    45010      10567          4671         3.813103   \n",
       "\n",
       "   avg_sentence_length  lexical_richness  \n",
       "0            26.601317         51.471545  \n",
       "1            20.250994         24.400159  \n",
       "2            15.417285         18.601775  \n",
       "3             4.259487          7.342539  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(summary_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d00c4c8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'corpus': 'gutenberg',\n",
       "  'characters': 11793318,\n",
       "  'words': 2621613,\n",
       "  'sentences': 98552,\n",
       "  'unique_words': 41487,\n",
       "  'avg_word_length': 4.178883581530393,\n",
       "  'avg_sentence_length': 26.601317071190845,\n",
       "  'lexical_richness': 51.47154530334804},\n",
       " {'corpus': 'brown',\n",
       "  'characters': 9964284,\n",
       "  'words': 1161192,\n",
       "  'sentences': 57340,\n",
       "  'unique_words': 40234,\n",
       "  'avg_word_length': 4.683248515864059,\n",
       "  'avg_sentence_length': 20.250994070456922,\n",
       "  'lexical_richness': 24.400159069443752},\n",
       " {'corpus': 'webtext',\n",
       "  'characters': 1726164,\n",
       "  'words': 396733,\n",
       "  'sentences': 25733,\n",
       "  'unique_words': 16453,\n",
       "  'avg_word_length': 4.262978876345755,\n",
       "  'avg_sentence_length': 15.417285197994792,\n",
       "  'lexical_richness': 18.601774752324804},\n",
       " {'corpus': 'nps_chat',\n",
       "  'characters': 2568552,\n",
       "  'words': 45010,\n",
       "  'sentences': 10567,\n",
       "  'unique_words': 4671,\n",
       "  'avg_word_length': 3.813103186867656,\n",
       "  'avg_sentence_length': 4.259487082426422,\n",
       "  'lexical_richness': 7.34253907086277}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "15207c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus.reader import XMLCorpusReader\n",
    "\n",
    "corpus_root = '.'  \n",
    "makhzan = XMLCorpusReader(corpus_root, 'corpus.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33369bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "num_paragraphs = 0\n",
    "for fileid in makhzan.fileids():\n",
    "    paras = makhzan.xml(fileid).findall('.//body/section/p')\n",
    "    num_paragraphs += len(paras)\n",
    "    for p in paras:\n",
    "        if p.text:\n",
    "            words.extend(p.text.split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e15637d",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_words = len(words)\n",
    "total_characters = sum(len(w) for w in words)\n",
    "unique_words = len(set(words))\n",
    "total_sentences = sum(w.count('Û”') for w in words)  \n",
    "if total_sentences == 0:\n",
    "    total_sentences = num_paragraphs  \n",
    "avg_word_length = total_characters / total_words if total_words else 0\n",
    "avg_sentence_length = total_words / total_sentences if total_sentences else 0\n",
    "lexical_richness = total_words / unique_words if unique_words else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "95f032b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words: 72\n",
      "Total characters: 255\n",
      "Total sentences: 3\n",
      "Unique words: 63\n",
      "Avg word length: 3.5416666666666665\n",
      "Avg sentence length: 24.0\n",
      "Lexical richness: 1.1428571428571428\n"
     ]
    }
   ],
   "source": [
    "print(\"Total words:\", total_words)\n",
    "print(\"Total characters:\", total_characters)\n",
    "print(\"Total sentences:\", total_sentences)\n",
    "print(\"Unique words:\", unique_words)\n",
    "print(\"Avg word length:\", avg_word_length)\n",
    "print(\"Avg sentence length:\", avg_sentence_length)\n",
    "print(\"Lexical richness:\", lexical_richness)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5142d3",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc501f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from nltk import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "289dda13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TF(word, text):\n",
    "    return math.log10(text.count(word) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bfdf63f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IDF(word, corpus_texts):\n",
    "    N = len(corpus_texts)\n",
    "    DF = sum(1 for t in corpus_texts if word in set(t))\n",
    "    return math.log10(N / (DF if DF else 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d53c1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TFIDF(word, text, corpus_texts):\n",
    "    return TF(word, text) * IDF(word, corpus_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b891ca37",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [text1, text2, text3,text4, text5, text6, text7, text8, text9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7a865504",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist1 = FreqDist(text1)\n",
    "words = sorted(set([w for w in text1 if w.isalpha()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "016a858a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text 1 analysis\n",
    "longwords = [w for w in words if len(w) == 16]\n",
    "words_ending_ed = [w for w in words if w.endswith('ed')]\n",
    "highfreq = [w for w in words if fdist1[w] >= 500]\n",
    "probability = lambda w: text1.count(w) / len(text1)\n",
    "prob_005 = [w for w in words if 0 < probability(w) < 0.05]\n",
    "prob_051 = [w for w in words if 0.05 <= probability(w) < 0.1]\n",
    "prob_1100 = [w for w in words if 0.1 <= probability(w) < 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "46b8fff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text 2 analysis\n",
    "fdist2 = FreqDist(text2)\n",
    "words2 = sorted(set([w for w in text2 if w.isalpha()]))\n",
    "\n",
    "longwords = [w for w in words if len(w) == 16]\n",
    "words_ending_ed = [w for w in words if w.endswith('ed')]\n",
    "highfreq = [w for w in words if fdist2[w] >= 500]\n",
    "probability = lambda w: text1.count(w) / len(text2)\n",
    "prob_005 = [w for w in words if 0 < probability(w) < 0.05]\n",
    "prob_051 = [w for w in words if 0.05 <= probability(w) < 0.1]\n",
    "prob_1100 = [w for w in words if 0.1 <= probability(w) < 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1699b10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text 3 analysis\n",
    "fdist3 = FreqDist(text3)\n",
    "words3 = sorted(set([w for w in text3 if w.isalpha()]))\n",
    "\n",
    "longwords3 = [w for w in words if len(w) == 16]\n",
    "words3_ending_ed = [w for w in words if w.endswith('ed')]\n",
    "highfreq3 = [w for w in words if fdist3[w] >= 500]\n",
    "probability3 = lambda w: text1.count(w) / len(text3)\n",
    "prob_005_3 = [w for w in words if 0 < probability(w) < 0.05]\n",
    "prob_051_3 = [w for w in words if 0.05 <= probability(w) < 0.1]\n",
    "prob_1100_3 = [w for w in words if 0.1 <= probability(w) < 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c92cf342",
   "metadata": {},
   "outputs": [],
   "source": [
    "seven_length = [w for w in words if len(w) == 7]\n",
    "top3 = sorted(seven_length, key=lambda w: probability(w), reverse=True)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b7df50e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "seven_length = [w for w in words2 if len(w) == 7]\n",
    "top3 = sorted(seven_length, key=lambda w: probability(w), reverse=True)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3418ea83",
   "metadata": {},
   "outputs": [],
   "source": [
    "seven_length = [w for w in words3 if len(w) == 7]\n",
    "top3 = sorted(seven_length, key=lambda w: probability(w), reverse=True)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "61b2f303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words with length 16: 13\n",
      "Number of words ending in 'ed': 2196\n",
      "Number of words with frequency >= 500: 58\n",
      "Number of words with probability between 0 and 0.05: 19031\n",
      "Number with probability 0.05 to 0.1: 1\n",
      "Number with probability 0.1 to 100: 0\n",
      "Top 3 words with length 7 and highest probability: ['through', 'Captain', 'himself']\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of words with length 16:\", len(longwords))\n",
    "print(\"Number of words ending in 'ed':\", len(words_ending_ed))\n",
    "print(\"Number of words with frequency >= 500:\", len(highfreq))\n",
    "print(\"Number of words with probability between 0 and 0.05:\", len(prob_005))\n",
    "print(\"Number with probability 0.05 to 0.1:\", len(prob_051))\n",
    "print(\"Number with probability 0.1 to 100:\", len(prob_1100))\n",
    "print(\"Top 3 words with length 7 and highest probability:\", top3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2a41f27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words with length 16: 13\n",
      "Number of words ending in 'ed': 2196\n",
      "Number of words with frequency >= 500: 37\n",
      "Number of words with probability between 0 and 0.05: 19031\n",
      "Number with probability 0.05 to 0.1: 1\n",
      "Number with probability 0.1 to 100: 0\n",
      "Top 3 words with length 7 and highest probability: ['through', 'himself', 'without']\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of words with length 16:\", len(longwords))\n",
    "print(\"Number of words ending in 'ed':\", len(words_ending_ed))\n",
    "print(\"Number of words with frequency >= 500:\", len(highfreq))\n",
    "print(\"Number of words with probability between 0 and 0.05:\", len(prob_005))\n",
    "print(\"Number with probability 0.05 to 0.1:\", len(prob_051))\n",
    "print(\"Number with probability 0.1 to 100:\", len(prob_1100))\n",
    "print(\"Top 3 words with length 7 and highest probability:\", top3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7f528bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words with length 16: 13\n",
      "Number of words ending in 'ed': 2196\n",
      "Number of words with frequency >= 500: 10\n",
      "Number of words with probability between 0 and 0.05: 19031\n",
      "Number with probability 0.05 to 0.1: 1\n",
      "Number with probability 0.1 to 100: 0\n",
      "Top 3 words with length 7 and highest probability: ['through', 'himself', 'without']\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of words with length 16:\", len(longwords3))\n",
    "print(\"Number of words ending in 'ed':\", len(words3_ending_ed))\n",
    "print(\"Number of words with frequency >= 500:\", len(highfreq3))\n",
    "print(\"Number of words with probability between 0 and 0.05:\", len(prob_005_3))\n",
    "print(\"Number with probability 0.05 to 0.1:\", len(prob_051_3))\n",
    "print(\"Number with probability 0.1 to 100:\", len(prob_1100_3))\n",
    "print(\"Top 3 words with length 7 and highest probability:\", top3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400b921c",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8269d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 frequent bigrams: [((',', 'and'), 2607), (('of', 'the'), 1847), ((\"'\", 's'), 1737), (('in', 'the'), 1120), ((',', 'the'), 908), ((';', 'and'), 853), (('to', 'the'), 712), (('.', 'But'), 596), ((',', 'that'), 584), (('.', '\"'), 557)]\n",
      "10 frequent collocations: [(',', 'and'), ('of', 'the'), (\"'\", 's'), ('in', 'the'), (',', 'the'), (';', 'and'), ('to', 'the'), ('.', 'But'), (',', 'that'), ('.', '\"')]\n",
      "5 frequent trigrams: [((',', 'and', 'the'), 187), (('don', \"'\", 't'), 103), (('of', 'the', 'whale'), 101), ((',', 'in', 'the'), 93), ((',', 'then', ','), 87)]\n"
     ]
    }
   ],
   "source": [
    "from nltk import bigrams, trigrams, FreqDist\n",
    "from nltk.collocations import BigramCollocationFinder, TrigramCollocationFinder, TrigramAssocMeasures\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "\n",
    "# text 1\n",
    "bigrams_text1 = list(bigrams(text1))\n",
    "fdist_bigram = FreqDist(bigrams_text1)\n",
    "common_bigrams = fdist_bigram.most_common(10)\n",
    "print(\"10 frequent bigrams:\", common_bigrams)\n",
    "\n",
    "bcf = BigramCollocationFinder.from_words(text1)\n",
    "\n",
    "collocs = bcf.nbest(BigramAssocMeasures.raw_freq, 10)  \n",
    "print(\"10 frequent collocations:\", collocs)\n",
    "\n",
    "trigrams_text1 = list(trigrams(text1))\n",
    "fdist_trigram = FreqDist(trigrams_text1)\n",
    "common_trigrams = fdist_trigram.most_common(5)\n",
    "print(\"5 frequent trigrams:\", common_trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "69a347d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 frequent bigrams: [((',', 'and'), 1598), ((\"'\", 's'), 700), ((';', 'and'), 605), (('Mrs', '.'), 529), (('of', 'the'), 430), (('to', 'be'), 428), (('.\"', '\"'), 428), ((',', '\"'), 392), (('.', '\"'), 369), (('in', 'the'), 348)]\n",
      "10 frequent collocations: [(',', 'and'), (\"'\", 's'), (';', 'and'), ('Mrs', '.'), ('of', 'the'), ('.\"', '\"'), ('to', 'be'), (',', '\"'), ('.', '\"'), ('in', 'the')]\n",
      "5 frequent trigrams: [(('Mrs', '.', 'Jennings'), 230), (('Mrs', '.', 'Dashwood'), 121), ((',', 'however', ','), 88), ((',', 'and', 'the'), 87), (('.', 'Mrs', '.'), 80)]\n"
     ]
    }
   ],
   "source": [
    "# text 2\n",
    "bigrams_text2 = list(bigrams(text2))\n",
    "fdist_bigram = FreqDist(bigrams_text2)\n",
    "common_bigrams = fdist_bigram.most_common(10)\n",
    "print(\"10 frequent bigrams:\", common_bigrams)\n",
    "\n",
    "bcf = BigramCollocationFinder.from_words(text2)\n",
    "\n",
    "collocs = bcf.nbest(BigramAssocMeasures.raw_freq, 10)  \n",
    "print(\"10 frequent collocations:\", collocs)\n",
    "\n",
    "trigrams_text2 = list(trigrams(text2))\n",
    "fdist_trigram = FreqDist(trigrams_text2)\n",
    "common_trigrams = fdist_trigram.most_common(5)\n",
    "print(\"5 frequent trigrams:\", common_trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1d7ad0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 frequent bigrams: [((',', 'and'), 1491), (('.', 'And'), 1038), (('of', 'the'), 372), (('in', 'the'), 287), ((';', 'and'), 262), (('said', ','), 259), ((\"'\", 's'), 255), (('And', 'he'), 192), (('And', 'the'), 185), (('said', 'unto'), 178)]\n",
      "10 frequent collocations: [(',', 'and'), ('.', 'And'), ('of', 'the'), ('in', 'the'), (';', 'and'), ('said', ','), (\"'\", 's'), ('And', 'he'), ('And', 'the'), ('said', 'unto')]\n",
      "5 frequent trigrams: [(('.', 'And', 'he'), 162), (('.', 'And', 'the'), 158), (('the', 'land', 'of'), 101), (('he', 'said', ','), 86), (('And', 'he', 'said'), 84)]\n"
     ]
    }
   ],
   "source": [
    "# text 3\n",
    "bigrams_text3 = list(bigrams(text3))\n",
    "fdist_bigram = FreqDist(bigrams_text3)\n",
    "common_bigrams = fdist_bigram.most_common(10)\n",
    "print(\"10 frequent bigrams:\", common_bigrams)\n",
    "\n",
    "bcf = BigramCollocationFinder.from_words(text3)\n",
    "\n",
    "collocs = bcf.nbest(BigramAssocMeasures.raw_freq, 10)  \n",
    "print(\"10 frequent collocations:\", collocs)\n",
    "\n",
    "trigrams_text3 = list(trigrams(text3))\n",
    "fdist_trigram = FreqDist(trigrams_text3)\n",
    "common_trigrams = fdist_trigram.most_common(5)\n",
    "print(\"5 frequent trigrams:\", common_trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d8adda3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 frequent bigrams: [(('of', 'the'), 1784), ((',', 'and'), 1404), (('in', 'the'), 765), (('to', 'the'), 716), (('of', 'our'), 635), (('.', 'The'), 606), (('.', 'We'), 562), (('and', 'the'), 470), ((',', 'the'), 388), (('.', 'It'), 354)]\n",
      "10 frequent collocations: [('of', 'the'), (',', 'and'), ('in', 'the'), ('to', 'the'), ('of', 'our'), ('.', 'The'), ('.', 'We'), ('and', 'the'), (',', 'the'), ('.', 'It')]\n",
      "5 frequent trigrams: [(('.', 'It', 'is'), 155), (('the', 'United', 'States'), 154), ((',', 'and', 'the'), 145), (('.', 'We', 'have'), 102), (('of', 'the', 'United'), 101)]\n"
     ]
    }
   ],
   "source": [
    "# text 4\n",
    "bigrams_text4 = list(bigrams(text4))\n",
    "fdist_bigram = FreqDist(bigrams_text4)\n",
    "common_bigrams = fdist_bigram.most_common(10)\n",
    "print(\"10 frequent bigrams:\", common_bigrams)\n",
    "\n",
    "bcf = BigramCollocationFinder.from_words(text4)\n",
    "\n",
    "collocs = bcf.nbest(BigramAssocMeasures.raw_freq, 10)  \n",
    "print(\"10 frequent collocations:\", collocs)\n",
    "\n",
    "trigrams_text4 = list(trigrams(text4))\n",
    "fdist_trigram = FreqDist(trigrams_text4)\n",
    "common_trigrams = fdist_trigram.most_common(5)\n",
    "print(\"5 frequent trigrams:\", common_trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cde618ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 frequent bigrams: [(('.', 'ACTION'), 346), (('PART', 'JOIN'), 191), (('JOIN', 'PART'), 136), (('PART', 'PART'), 115), (('JOIN', 'JOIN'), 107), (('I', \"'m\"), 89), (('.', 'JOIN'), 79), (('pm', 'me'), 76), (('in', 'the'), 75), (('are', 'you'), 65)]\n",
      "10 frequent collocations: [('.', 'ACTION'), ('PART', 'JOIN'), ('JOIN', 'PART'), ('PART', 'PART'), ('JOIN', 'JOIN'), ('I', \"'m\"), ('.', 'JOIN'), ('pm', 'me'), ('in', 'the'), ('are', 'you')]\n",
      "5 frequent trigrams: [(('PART', 'JOIN', 'PART'), 35), (('JOIN', '.', 'ACTION'), 34), (('.', 'ACTION', 'is'), 33), (('JOIN', 'PART', 'JOIN'), 33), (('PART', 'JOIN', 'JOIN'), 25)]\n"
     ]
    }
   ],
   "source": [
    "# text 5\n",
    "bigrams_text5 = list(bigrams(text5))\n",
    "fdist_bigram = FreqDist(bigrams_text5)\n",
    "common_bigrams = fdist_bigram.most_common(10)\n",
    "print(\"10 frequent bigrams:\", common_bigrams)\n",
    "\n",
    "bcf = BigramCollocationFinder.from_words(text5)\n",
    "\n",
    "collocs = bcf.nbest(BigramAssocMeasures.raw_freq, 10)  \n",
    "print(\"10 frequent collocations:\", collocs)\n",
    "\n",
    "trigrams_text5 = list(trigrams(text5))\n",
    "fdist_trigram = FreqDist(trigrams_text5)\n",
    "common_trigrams = fdist_trigram.most_common(5)\n",
    "print(\"5 frequent trigrams:\", common_trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0f0467",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
